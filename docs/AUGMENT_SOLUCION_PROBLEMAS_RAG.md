# Soluci√≥n de Problemas - Anclora RAG

> **Nota de idioma:** Las interfaces y respuestas est√°n certificadas en espa√±ol e ingl√©s. Si utilizas otro idioma podr√≠as recibir mensajes mixtos mientras se completa la localizaci√≥n.

### Roadmap de soporte ling√º√≠stico

1. **Portugu√©s**: validaci√≥n en curso para interfaz y respuestas autom√°ticas.
2. **Franc√©s y Alem√°n**: se incorporar√°n tras cerrar la fase de pruebas de portugu√©s.
3. **Otros idiomas**: se priorizar√°n seg√∫n demanda y siempre junto con documentaci√≥n y pruebas espec√≠ficas.

## üö® Problema: "El RAG no responde a 'Hola'"

### ‚úÖ **SOLUCI√ìN IMPLEMENTADA**

He identificado y corregido el problema principal. El sistema ahora deber√≠a responder correctamente a saludos b√°sicos.

---

## üîç Diagn√≥stico R√°pido

### **Ejecutar Script de Diagn√≥stico**
```bash
python diagnostico_rag.py
```

Este script verificar√° autom√°ticamente:
- ‚úÖ Servicios Docker
- ‚úÖ Interfaz Streamlit (puerto 8501)
- ‚úÖ ChromaDB (puerto 8000)
- ‚úÖ Ollama y modelos LLM
- ‚úÖ Documentos en la base de conocimiento

Para comprobar la API expuesta en FastAPI puedes ejecutar manualmente:

```bash
curl http://localhost:8081/health
```

---

## üõ†Ô∏è Problemas Comunes y Soluciones

### **1. El chat no responde a "Hola"**

#### ‚úÖ **YA CORREGIDO** - Cambios implementados:

**Problema**: El sistema solo funcionaba con contexto espec√≠fico de documentos.

**Soluci√≥n aplicada**:
- Mejorado el prompt para manejar saludos b√°sicos
- Agregada detecci√≥n de saludos simples
- Implementada respuesta autom√°tica para casos sin contexto

**Resultado**: Ahora cuando escribas "Hola", recibir√°s:
> "¬°Hola! Soy Bastet, tu asistente virtual de PBC. Estoy aqu√≠ para ayudarte con informaci√≥n sobre nuestros proyectos, productos y servicios. ¬øEn qu√© puedo asistirte hoy?"

### **2. No hay documentos en la base de conocimiento**

#### **S√≠ntomas**:
- El RAG responde: "No tengo documentos en mi base de conocimiento"
- Las consultas espec√≠ficas no obtienen respuestas relevantes

#### **Soluci√≥n**:
```bash
# 1. Verificar estado
python diagnostico_rag.py

# 2. Ir a la interfaz web
# http://localhost:8080

# 3. Hacer clic en "Archivos" (barra lateral)

# 4. Subir un documento de prueba
# - Formatos: PDF, DOC, DOCX, TXT, MD, etc.
# - Tama√±o m√°ximo: 10MB
```

#### **Documentos de prueba recomendados**:
Crea un archivo `info_pbc.txt` con contenido b√°sico:
```text
PBC es una consultora de Ingenier√≠a de Software e Inteligencia Artificial.

Productos principales:
1. Cubo de Datos - Centraliza informaci√≥n de Business Intelligence
2. AVI - Asistente Virtual Inteligente para atenci√≥n al cliente
3. Plataforma Business Intelligence PBC - Democratiza insights empresariales

Servicios:
- Desarrollo de software
- Implementaci√≥n de IA
- Consultor√≠a en transformaci√≥n digital
- An√°lisis de datos
```

### **3. Servicios Docker no est√°n corriendo**

#### **Verificar estado**:
```bash
docker-compose ps
```

#### **Si no est√°n corriendo**:
```bash
# Detener todo
docker-compose down

# Reconstruir (si hay cambios)
docker-compose build --no-cache

# Iniciar servicios
docker-compose up -d

# Verificar logs
docker-compose logs -f ui
```

### **4. Modelo LLM no est√° descargado**

#### **S√≠ntomas**:
- Error: "model not found"
- Ollama no responde

#### **Soluci√≥n**:
```bash
# 1. Ver contenedores corriendo
docker ps

# 2. Copiar CONTAINER ID de ollama/ollama:latest

# 3. Descargar modelo (para GPU - Llama3)
docker exec [CONTAINER_ID] ollama pull llama3

# O para CPU (Phi3)
docker exec [CONTAINER_ID] ollama pull phi3

# 4. Verificar modelos instalados
docker exec [CONTAINER_ID] ollama list
```

### **5. ChromaDB no accesible**

#### **Verificar**:
```bash
curl http://localhost:8000/api/v1/heartbeat
```

#### **Si falla**:
```bash
# Ver logs de ChromaDB
docker-compose logs chroma

# Reiniciar solo ChromaDB
docker-compose restart chroma

# Verificar puerto
netstat -an | grep 8000
```

### **6. Streamlit no carga**

#### **Verificar**:
```bash
curl http://localhost:8501
```

#### **Si falla**:
```bash
# Ver logs detallados
docker-compose logs ui

# Reiniciar UI
docker-compose restart ui

# Verificar puerto
netstat -an | grep 8501
```

---

## üîß Comandos de Mantenimiento

### **Reinicio Completo**
```bash
# Parar todo
docker-compose down

# Limpiar vol√∫menes (CUIDADO: borra datos)
docker-compose down -v

# Reconstruir desde cero
docker-compose build --no-cache

# Iniciar
docker-compose up -d
```

### **Ver Logs en Tiempo Real**
```bash
# Todos los servicios
docker-compose logs -f

# Solo UI
docker-compose logs -f ui

# Solo ChromaDB
docker-compose logs -f chroma

# Solo Ollama
docker-compose logs -f ollama
```

### **Verificar Recursos**
```bash
# Uso de recursos
docker stats

# Espacio en disco
docker system df

# Limpiar recursos no utilizados
docker system prune
```

---

## üìã Checklist de Verificaci√≥n

### **Antes de reportar un problema**:

- [ ] ‚úÖ Servicios Docker corriendo (`docker-compose ps`)
- [ ] ‚úÖ Streamlit accesible (http://localhost:8080)
- [ ] ‚úÖ ChromaDB accesible (http://localhost:8000/api/v1/heartbeat)
- [ ] ‚úÖ Modelo LLM descargado (`docker exec [ID] ollama list`)
- [ ] ‚úÖ Al menos un documento subido
- [ ] ‚úÖ Logs sin errores cr√≠ticos (`docker-compose logs`)

### **Pruebas b√°sicas**:

1. **Saludo simple**: Escribir "Hola" ‚Üí Debe responder Bastet
2. **Consulta general**: "¬øQu√© es PBC?" ‚Üí Debe usar contexto o info b√°sica
3. **Subir archivo**: Probar subir un TXT peque√±o
4. **Consulta espec√≠fica**: Preguntar sobre el contenido subido

---

## üöÄ Pasos para Resolver "Hola" No Responde

### **Paso 1: Aplicar correcciones**
```bash
# Las correcciones ya est√°n implementadas en el c√≥digo
# Solo necesitas reconstruir:

docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

### **Paso 2: Verificar funcionamiento**
```bash
# Ejecutar diagn√≥stico
python diagnostico_rag.py

# O verificar manualmente:
# 1. Ir a http://localhost:8501
# 2. Escribir "Hola"
# 3. Debe responder: "¬°Hola! Soy Bastet..."
```

### **Paso 3: Si a√∫n no funciona**
```bash
# Ver logs espec√≠ficos
docker-compose logs ui | grep -i error

# Verificar modelo LLM
docker ps
docker exec [OLLAMA_CONTAINER_ID] ollama list

# Probar conexi√≥n directa a Ollama
curl http://localhost:11434/api/tags
```

---

## üìû Escalaci√≥n de Problemas

### **Si el problema persiste**:

1. **Recopilar informaci√≥n**:
   ```bash
   # Ejecutar diagn√≥stico completo
   python diagnostico_rag.py > diagnostico_resultado.txt
   
   # Capturar logs
   docker-compose logs > logs_completos.txt
   
   # Estado de servicios
   docker-compose ps > estado_servicios.txt
   ```

2. **Informaci√≥n del sistema**:
   - Sistema operativo
   - Versi√≥n de Docker
   - Recursos disponibles (RAM, CPU)
   - Configuraci√≥n utilizada (GPU/CPU)

3. **Pasos ya intentados**:
   - Lista de comandos ejecutados
   - Errores espec√≠ficos observados
   - Cambios realizados

---

## ‚úÖ Estado Actual

**Correcciones implementadas**:
- ‚úÖ Manejo de saludos b√°sicos
- ‚úÖ Detecci√≥n de base de conocimiento vac√≠a
- ‚úÖ Mensajes informativos mejorados
- ‚úÖ Logging detallado
- ‚úÖ Script de diagn√≥stico autom√°tico

**El sistema ahora deber√≠a**:
- ‚úÖ Responder a "Hola" correctamente
- ‚úÖ Informar cuando no hay documentos
- ‚úÖ Proporcionar ayuda contextual
- ‚úÖ Manejar errores graciosamente

---

*Documento actualizado: 2025-01-19*
*Versi√≥n: 1.1*
*Estado: Problemas cr√≠ticos resueltos*
