#!/usr/bin/env python3
"""
Script para analizar y mejorar el chunking de c√≥digo en Anclora RAG.
Esto es crucial para recuperar fragmentos de c√≥digo precisos de la base vectorial.
"""

import sys
import os
from pathlib import Path

# Add the app directory to the path
current_dir = Path(__file__).parent
app_dir = current_dir / "app"
if str(app_dir) not in sys.path:
    sys.path.insert(0, str(app_dir))

def analyze_current_chunking():
    """Analiza la configuraci√≥n actual de chunking"""
    
    print("üîç AN√ÅLISIS DEL CHUNKING ACTUAL")
    print("=" * 50)
    
    try:
        from common.ingest_file import CHUNK_SIZE, CHUNK_OVERLAP
        print(f"üìè Tama√±o de chunk actual: {CHUNK_SIZE} caracteres")
        print(f"üîó Overlap actual: {CHUNK_OVERLAP} caracteres")
        print(f"üìä Ratio de overlap: {(CHUNK_OVERLAP/CHUNK_SIZE)*100:.1f}%")
    except Exception as e:
        print(f"‚ùå Error obteniendo configuraci√≥n: {e}")
        return None
    
    return {"chunk_size": CHUNK_SIZE, "chunk_overlap": CHUNK_OVERLAP}

def test_code_chunking_examples():
    """Prueba el chunking con ejemplos de c√≥digo"""
    
    print("\nüß™ PRUEBAS DE CHUNKING CON C√ìDIGO")
    print("=" * 50)
    
    # Ejemplos de c√≥digo de diferentes lenguajes
    code_examples = {
        "python_function": '''
def process_document(file_path, chunk_size=500):
    """
    Procesa un documento y lo divide en chunks.
    
    Args:
        file_path (str): Ruta al archivo
        chunk_size (int): Tama√±o del chunk
    
    Returns:
        List[str]: Lista de chunks procesados
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    chunks = []
    for i in range(0, len(content), chunk_size):
        chunk = content[i:i + chunk_size]
        chunks.append(chunk.strip())
    
    return chunks
''',
        
        "javascript_class": '''
class DocumentProcessor {
    constructor(options = {}) {
        this.chunkSize = options.chunkSize || 500;
        this.overlap = options.overlap || 50;
        this.language = options.language || 'auto';
    }
    
    async processFile(filePath) {
        try {
            const content = await fs.readFile(filePath, 'utf8');
            return this.createChunks(content);
        } catch (error) {
            console.error('Error processing file:', error);
            throw error;
        }
    }
    
    createChunks(text) {
        const chunks = [];
        let start = 0;
        
        while (start < text.length) {
            const end = Math.min(start + this.chunkSize, text.length);
            const chunk = text.slice(start, end);
            chunks.push(chunk.trim());
            start += this.chunkSize - this.overlap;
        }
        
        return chunks;
    }
}
''',
        
        "sql_query": '''
-- Consulta compleja para an√°lisis de documentos
WITH document_stats AS (
    SELECT 
        d.id,
        d.title,
        d.file_type,
        COUNT(c.id) as chunk_count,
        AVG(LENGTH(c.content)) as avg_chunk_size,
        MAX(c.created_at) as last_processed
    FROM documents d
    LEFT JOIN chunks c ON d.id = c.document_id
    WHERE d.created_at >= DATE_SUB(NOW(), INTERVAL 30 DAY)
    GROUP BY d.id, d.title, d.file_type
),
processing_metrics AS (
    SELECT 
        file_type,
        COUNT(*) as total_docs,
        AVG(chunk_count) as avg_chunks_per_doc,
        AVG(avg_chunk_size) as overall_avg_chunk_size
    FROM document_stats
    GROUP BY file_type
)
SELECT 
    pm.file_type,
    pm.total_docs,
    ROUND(pm.avg_chunks_per_doc, 2) as avg_chunks,
    ROUND(pm.overall_avg_chunk_size, 2) as avg_size
FROM processing_metrics pm
ORDER BY pm.total_docs DESC;
'''
    }
    
    try:
        from langchain.text_splitter import RecursiveCharacterTextSplitter
        
        # Configuraci√≥n actual
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50
        )
        
        for name, code in code_examples.items():
            print(f"\nüìù Ejemplo: {name}")
            print("-" * 30)
            
            chunks = splitter.split_text(code)
            print(f"üî¢ N√∫mero de chunks: {len(chunks)}")
            
            for i, chunk in enumerate(chunks):
                lines = chunk.count('\n') + 1
                chars = len(chunk)
                print(f"  Chunk {i+1}: {chars} chars, {lines} l√≠neas")
                
                # Mostrar primeras l√≠neas del chunk
                first_lines = '\n'.join(chunk.split('\n')[:3])
                print(f"  Contenido: {first_lines[:100]}...")
                print()
                
    except Exception as e:
        print(f"‚ùå Error en pruebas de chunking: {e}")

def recommend_code_chunking_improvements():
    """Recomienda mejoras para el chunking de c√≥digo"""
    
    print("\nüí° RECOMENDACIONES PARA MEJORAR EL CHUNKING DE C√ìDIGO")
    print("=" * 60)
    
    recommendations = [
        {
            "title": "üéØ Chunking espec√≠fico por lenguaje",
            "description": "Usar diferentes estrategias seg√∫n el tipo de archivo",
            "implementation": "Implementar CodeTextSplitter de LangChain con soporte para m√∫ltiples lenguajes"
        },
        {
            "title": "üîç Preservar contexto sem√°ntico",
            "description": "Mantener funciones, clases y bloques de c√≥digo completos",
            "implementation": "Usar separadores espec√≠ficos como '\\n\\nclass ', '\\n\\ndef ', '\\n\\nfunction '"
        },
        {
            "title": "üìè Tama√±os adaptativos",
            "description": "Ajustar tama√±o de chunk seg√∫n el tipo de contenido",
            "implementation": "C√≥digo: 1000-1500 chars, Documentaci√≥n: 500-800 chars"
        },
        {
            "title": "üè∑Ô∏è Metadatos enriquecidos",
            "description": "Agregar informaci√≥n sobre el contexto del c√≥digo",
            "implementation": "Incluir: lenguaje, tipo (funci√≥n/clase/comentario), l√≠nea de inicio"
        },
        {
            "title": "üîó Overlap inteligente",
            "description": "Overlap basado en estructura, no solo caracteres",
            "implementation": "Mantener imports, definiciones de clase en chunks relacionados"
        }
    ]
    
    for i, rec in enumerate(recommendations, 1):
        print(f"{i}. {rec['title']}")
        print(f"   üìã {rec['description']}")
        print(f"   üõ†Ô∏è  {rec['implementation']}")
        print()

def create_improved_chunking_config():
    """Crea una configuraci√≥n mejorada para chunking de c√≥digo"""
    
    print("\n‚öôÔ∏è CONFIGURACI√ìN MEJORADA PROPUESTA")
    print("=" * 50)
    
    config = {
        "code_files": {
            "chunk_size": 1200,
            "chunk_overlap": 100,
            "separators": [
                "\n\nclass ",
                "\n\ndef ",
                "\n\nfunction ",
                "\n\n# ",
                "\n\n// ",
                "\n\n/*",
                "\n\n",
                "\n",
                " "
            ]
        },
        "documentation": {
            "chunk_size": 800,
            "chunk_overlap": 80,
            "separators": [
                "\n\n## ",
                "\n\n### ",
                "\n\n",
                "\n",
                ". ",
                " "
            ]
        },
        "mixed_content": {
            "chunk_size": 1000,
            "chunk_overlap": 100,
            "separators": [
                "\n\n```",
                "\n\nclass ",
                "\n\ndef ",
                "\n\n## ",
                "\n\n",
                "\n",
                " "
            ]
        }
    }
    
    for content_type, settings in config.items():
        print(f"üìÅ {content_type.upper()}:")
        print(f"   Tama√±o: {settings['chunk_size']} caracteres")
        print(f"   Overlap: {settings['chunk_overlap']} caracteres")
        print(f"   Separadores: {len(settings['separators'])} niveles")
        print()
    
    return config

def main():
    print("üîß ANALIZADOR DE CHUNKING DE C√ìDIGO - ANCLORA RAG")
    print("=" * 60)
    print("Optimizando la recuperaci√≥n precisa de fragmentos de c√≥digo")
    print()
    
    # Analizar configuraci√≥n actual
    current_config = analyze_current_chunking()
    
    # Probar con ejemplos de c√≥digo
    test_code_chunking_examples()
    
    # Generar recomendaciones
    recommend_code_chunking_improvements()
    
    # Crear configuraci√≥n mejorada
    improved_config = create_improved_chunking_config()
    
    print("üéØ PR√ìXIMOS PASOS:")
    print("1. Implementar CodeTextSplitter espec√≠fico por lenguaje")
    print("2. Agregar metadatos de contexto a los chunks")
    print("3. Probar con documentaci√≥n t√©cnica real")
    print("4. Medir precisi√≥n de recuperaci√≥n antes/despu√©s")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
