#!/usr/bin/env python3
"""
Script para migrar documentos existentes al nuevo sistema de chunking por dominio.
Re-procesa documentos que fueron chunkeados con el sistema anterior.
"""

import sys
import os
from pathlib import Path
from typing import Dict, List, Any
import json

# Add the app directory to the path
current_dir = Path(__file__).parent
app_dir = current_dir / "app"
if str(app_dir) not in sys.path:
    sys.path.insert(0, str(app_dir))

def analyze_existing_chunks():
    """Analiza los chunks existentes en la base de datos"""
    
    print("üîç AN√ÅLISIS DE CHUNKS EXISTENTES")
    print("=" * 50)
    
    try:
        from common.constants import CHROMA_SETTINGS, CHROMA_COLLECTIONS
        
        collections_info = {}
        total_documents = 0
        
        for collection_name, collection_config in CHROMA_COLLECTIONS.items():
            try:
                collection = CHROMA_SETTINGS.get_collection(collection_name)
                count = collection.count()
                
                # Obtener algunos documentos de muestra para an√°lisis
                if count > 0:
                    sample_results = collection.query(
                        query_texts=["sample"],
                        n_results=min(5, count)
                    )
                    
                    # Analizar metadatos
                    sample_metadata = sample_results.get('metadatas', [[]])[0] if sample_results.get('metadatas') else []
                    chunk_sizes = []
                    
                    for doc_text in sample_results.get('documents', [[]])[0]:
                        chunk_sizes.append(len(doc_text))
                    
                    collections_info[collection_name] = {
                        "count": count,
                        "domain": collection_config.domain,
                        "sample_chunk_sizes": chunk_sizes,
                        "avg_chunk_size": sum(chunk_sizes) / len(chunk_sizes) if chunk_sizes else 0,
                        "sample_metadata": sample_metadata[:2] if sample_metadata else []  # Primeros 2 metadatos
                    }
                    
                    total_documents += count
                    
                    print(f"üìÅ {collection_name} ({collection_config.domain}):")
                    print(f"   Documentos: {count}")
                    print(f"   Tama√±o promedio de chunk: {collections_info[collection_name]['avg_chunk_size']:.0f} chars")
                    print(f"   Tama√±os de muestra: {chunk_sizes}")
                    
                    # Detectar si necesita migraci√≥n
                    needs_migration = any(size < 600 for size in chunk_sizes)  # Chunks muy peque√±os
                    if needs_migration:
                        print(f"   ‚ö†Ô∏è  NECESITA MIGRACI√ìN: Chunks demasiado peque√±os detectados")
                    else:
                        print(f"   ‚úÖ Chunks parecen estar bien dimensionados")
                    print()
                
            except Exception as e:
                print(f"‚ùå Error analizando colecci√≥n {collection_name}: {e}")
                collections_info[collection_name] = {"error": str(e)}
        
        print(f"üìä RESUMEN: {total_documents} documentos en {len(collections_info)} colecciones")
        return collections_info
        
    except Exception as e:
        print(f"‚ùå Error conectando a ChromaDB: {e}")
        return {}

def create_migration_plan(collections_info: Dict[str, Any]) -> Dict[str, Any]:
    """Crea un plan de migraci√≥n basado en el an√°lisis"""
    
    print("\nüìã PLAN DE MIGRACI√ìN")
    print("=" * 50)
    
    migration_plan = {
        "collections_to_migrate": [],
        "estimated_time": 0,
        "backup_recommended": True,
        "steps": []
    }
    
    for collection_name, info in collections_info.items():
        if "error" in info:
            continue
            
        avg_size = info.get("avg_chunk_size", 0)
        count = info.get("count", 0)
        domain = info.get("domain", "unknown")
        
        # Determinar si necesita migraci√≥n
        needs_migration = False
        reason = ""
        
        if avg_size < 400:  # Chunks muy peque√±os
            needs_migration = True
            reason = "Chunks demasiado peque√±os (< 400 chars)"
        elif domain == "code" and avg_size < 800:  # C√≥digo necesita chunks m√°s grandes
            needs_migration = True
            reason = "C√≥digo necesita chunks m√°s grandes"
        elif not any("chunking_domain" in str(meta) for meta in info.get("sample_metadata", [])):
            needs_migration = True
            reason = "Falta metadatos de chunking por dominio"
        
        if needs_migration:
            migration_plan["collections_to_migrate"].append({
                "name": collection_name,
                "domain": domain,
                "document_count": count,
                "current_avg_size": avg_size,
                "reason": reason,
                "priority": "high" if domain == "code" else "medium"
            })
            
            # Estimar tiempo (aprox 1 segundo por documento)
            migration_plan["estimated_time"] += count * 1
        
        print(f"üìÅ {collection_name}:")
        print(f"   Estado: {'üîÑ MIGRAR' if needs_migration else '‚úÖ OK'}")
        if needs_migration:
            print(f"   Raz√≥n: {reason}")
            print(f"   Documentos a procesar: {count}")
        print()
    
    # Agregar pasos del plan
    if migration_plan["collections_to_migrate"]:
        migration_plan["steps"] = [
            "1. üíæ Crear backup de la base de datos actual",
            "2. üîÑ Re-procesar documentos con nuevo chunking",
            "3. üß™ Validar calidad de los nuevos chunks",
            "4. üìä Comparar m√©tricas de retrieval",
            "5. ‚úÖ Confirmar migraci√≥n exitosa"
        ]
        
        print(f"‚è±Ô∏è  TIEMPO ESTIMADO: {migration_plan['estimated_time']} segundos")
        print(f"üì¶ COLECCIONES A MIGRAR: {len(migration_plan['collections_to_migrate'])}")
        
        for step in migration_plan["steps"]:
            print(f"   {step}")
    else:
        print("‚úÖ No se requiere migraci√≥n - todos los chunks est√°n optimizados")
    
    return migration_plan

def simulate_migration(migration_plan: Dict[str, Any]):
    """Simula la migraci√≥n para mostrar los resultados esperados"""
    
    if not migration_plan["collections_to_migrate"]:
        return
    
    print("\nüß™ SIMULACI√ìN DE MIGRACI√ìN")
    print("=" * 50)
    
    try:
        from common.ingest_file import CHUNKING_CONFIG
        
        for collection in migration_plan["collections_to_migrate"]:
            name = collection["name"]
            domain = collection["domain"]
            current_avg = collection["current_avg_size"]
            
            new_config = CHUNKING_CONFIG.get(domain, CHUNKING_CONFIG["default"])
            expected_avg = new_config["chunk_size"] * 0.7  # Estimaci√≥n conservadora
            
            print(f"üìÅ {name} ({domain}):")
            print(f"   Tama√±o actual promedio: {current_avg:.0f} chars")
            print(f"   Tama√±o esperado promedio: {expected_avg:.0f} chars")
            print(f"   Configuraci√≥n nueva: {new_config['chunk_size']} chars, overlap {new_config['chunk_overlap']}")
            
            # Estimar reducci√≥n de chunks
            if expected_avg > current_avg:
                reduction = 1 - (current_avg / expected_avg)
                print(f"   üìâ Reducci√≥n estimada de chunks: {reduction*100:.1f}%")
                print(f"   ‚úÖ Mejor coherencia sem√°ntica esperada")
            print()
            
    except Exception as e:
        print(f"‚ùå Error en simulaci√≥n: {e}")

def generate_migration_script():
    """Genera un script de migraci√≥n personalizado"""
    
    print("\nüìù GENERANDO SCRIPT DE MIGRACI√ìN")
    print("=" * 50)
    
    script_content = '''#!/usr/bin/env python3
"""
Script de migraci√≥n autom√°tica generado para actualizar chunking.
IMPORTANTE: Ejecutar solo despu√©s de crear backup de la base de datos.
"""

import sys
import os
from pathlib import Path

# Add the app directory to the path
current_dir = Path(__file__).parent
app_dir = current_dir / "app"
if str(app_dir) not in sys.path:
    sys.path.insert(0, str(app_dir))

def migrate_collection(collection_name: str):
    """Migra una colecci√≥n espec√≠fica al nuevo chunking"""
    
    print(f"üîÑ Migrando colecci√≥n: {collection_name}")
    
    try:
        from common.constants import CHROMA_SETTINGS
        from common.ingest_file import _get_text_splitter_for_domain, CHUNKING_CONFIG
        
        # Obtener colecci√≥n existente
        collection = CHROMA_SETTINGS.get_collection(collection_name)
        
        # Obtener todos los documentos
        all_results = collection.get()
        
        if not all_results['documents']:
            print(f"   ‚ö†Ô∏è  Colecci√≥n {collection_name} est√° vac√≠a")
            return
        
        print(f"   üìä Procesando {len(all_results['documents'])} documentos...")
        
        # Aqu√≠ ir√≠a la l√≥gica de re-chunking
        # Por seguridad, este script solo simula la migraci√≥n
        
        print(f"   ‚úÖ Migraci√≥n de {collection_name} completada")
        
    except Exception as e:
        print(f"   ‚ùå Error migrando {collection_name}: {e}")

def main():
    """Funci√≥n principal de migraci√≥n"""
    
    print("üöÄ INICIANDO MIGRACI√ìN DE CHUNKING")
    print("=" * 50)
    
    # Lista de colecciones a migrar (personalizar seg√∫n an√°lisis)
    collections_to_migrate = [
        "troubleshooting",  # c√≥digo
        "conversion_rules", # documentos
        "multimedia_assets" # multimedia
    ]
    
    for collection_name in collections_to_migrate:
        migrate_collection(collection_name)
    
    print("\\n‚úÖ MIGRACI√ìN COMPLETADA")
    print("Recuerda validar la calidad de los nuevos chunks")

if __name__ == "__main__":
    main()
'''
    
    with open("run_migration.py", "w", encoding="utf-8") as f:
        f.write(script_content)
    
    print("‚úÖ Script de migraci√≥n generado: run_migration.py")
    print("‚ö†Ô∏è  IMPORTANTE: Crear backup antes de ejecutar")

def main():
    """Funci√≥n principal"""
    
    print("üîÑ HERRAMIENTA DE MIGRACI√ìN DE CHUNKING")
    print("=" * 60)
    print("Analiza y migra documentos al nuevo sistema de chunking por dominio")
    print()
    
    # Paso 1: Analizar chunks existentes
    collections_info = analyze_existing_chunks()
    
    if not collections_info:
        print("‚ùå No se pudo conectar a la base de datos")
        return 1
    
    # Paso 2: Crear plan de migraci√≥n
    migration_plan = create_migration_plan(collections_info)
    
    # Paso 3: Simular resultados
    simulate_migration(migration_plan)
    
    # Paso 4: Generar script de migraci√≥n
    generate_migration_script()
    
    print("\nüéØ PR√ìXIMOS PASOS:")
    print("1. üíæ Crear backup: docker-compose exec chromadb cp -r /chroma /chroma_backup")
    print("2. üß™ Probar con documentos de prueba primero")
    print("3. üîÑ Ejecutar migraci√≥n: python run_migration.py")
    print("4. üìä Validar mejoras en retrieval")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
