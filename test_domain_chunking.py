#!/usr/bin/env python3
"""
Script para probar el nuevo sistema de chunking por dominio.
Compara el chunking anterior vs el nuevo sistema diferenciado.
"""

import sys
import os
from pathlib import Path

# Add the app directory to the path
current_dir = Path(__file__).parent
app_dir = current_dir / "app"
if str(app_dir) not in sys.path:
    sys.path.insert(0, str(app_dir))

def test_domain_chunking():
    """Prueba el nuevo sistema de chunking por dominio"""
    
    print("üéØ PRUEBA DEL CHUNKING POR DOMINIO")
    print("=" * 50)
    
    try:
        from common.ingest_file import _get_text_splitter_for_domain, CHUNKING_CONFIG
        print("‚úÖ Funciones de chunking importadas correctamente")
    except Exception as e:
        print(f"‚ùå Error importando funciones: {e}")
        return
    
    # Ejemplos de contenido por dominio
    test_cases = {
        "code": {
            "domain": "code",
            "content": '''
import os
import sys
from typing import List, Dict, Optional

class DocumentProcessor:
    """Procesador de documentos con chunking inteligente"""
    
    def __init__(self, chunk_size: int = 1000):
        self.chunk_size = chunk_size
        self.processed_docs = []
    
    def process_file(self, file_path: str) -> List[str]:
        """
        Procesa un archivo y lo divide en chunks.
        
        Args:
            file_path: Ruta al archivo
            
        Returns:
            Lista de chunks procesados
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Archivo no encontrado: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        return self._create_chunks(content)
    
    def _create_chunks(self, content: str) -> List[str]:
        """Crea chunks del contenido"""
        chunks = []
        # L√≥gica de chunking aqu√≠...
        return chunks

def main():
    """Funci√≥n principal"""
    processor = DocumentProcessor()
    print("Sistema inicializado")
'''
        },
        
        "documents": {
            "domain": "documents",
            "content": '''
# Gu√≠a de Implementaci√≥n del Sistema RAG

## Introducci√≥n

El sistema RAG (Retrieval-Augmented Generation) combina la recuperaci√≥n de informaci√≥n con la generaci√≥n de texto para proporcionar respuestas precisas y contextuales.

## Arquitectura del Sistema

### Componentes Principales

1. **Base de Datos Vectorial**: ChromaDB para almacenar embeddings
2. **Modelo de Embeddings**: HuggingFace para convertir texto a vectores
3. **Modelo de Lenguaje**: Para generar respuestas basadas en contexto

### Flujo de Procesamiento

El procesamiento sigue estos pasos:

1. **Ingesta de Documentos**
   - Carga de archivos m√∫ltiples formatos
   - Chunking inteligente por tipo de contenido
   - Generaci√≥n de embeddings

2. **Consulta y Recuperaci√≥n**
   - An√°lisis de la consulta del usuario
   - B√∫squeda de similitud en la base vectorial
   - Selecci√≥n de chunks m√°s relevantes

3. **Generaci√≥n de Respuesta**
   - Construcci√≥n del contexto con chunks recuperados
   - Generaci√≥n de respuesta usando LLM
   - Post-procesamiento y validaci√≥n

## Configuraci√≥n Avanzada

### Par√°metros de Chunking

Para optimizar la recuperaci√≥n, se pueden ajustar:

- **Tama√±o de chunk**: Seg√∫n el tipo de contenido
- **Overlap**: Para mantener contexto entre chunks
- **Separadores**: Espec√≠ficos por formato de archivo

### M√©tricas de Evaluaci√≥n

- **Precisi√≥n**: Relevancia de documentos recuperados
- **Recall**: Cobertura de informaci√≥n relevante
- **Latencia**: Tiempo de respuesta del sistema
'''
        },
        
        "multimedia": {
            "domain": "multimedia", 
            "content": '''
Transcripci√≥n de audio: Presentaci√≥n sobre IA

Hola y bienvenidos a esta presentaci√≥n sobre inteligencia artificial. 

En los √∫ltimos a√±os hemos visto avances incre√≠bles en el campo de la IA, especialmente en el procesamiento de lenguaje natural y la visi√≥n por computadora.

Los modelos de lenguaje como GPT han revolucionado la forma en que interactuamos con las m√°quinas, permitiendo conversaciones m√°s naturales y la generaci√≥n de contenido de alta calidad.

En el √°mbito empresarial, la IA est√° transformando industrias enteras, desde la atenci√≥n al cliente hasta el an√°lisis de datos y la toma de decisiones automatizada.

Sin embargo, tambi√©n enfrentamos desaf√≠os importantes como la √©tica en IA, la privacidad de datos y la necesidad de transparencia en los algoritmos.

Es crucial que desarrollemos estas tecnolog√≠as de manera responsable, considerando su impacto en la sociedad y asegur√°ndonos de que beneficien a todos.

Gracias por su atenci√≥n y espero que esta informaci√≥n les sea √∫til.
'''
        }
    }
    
    print("\nüîç COMPARACI√ìN DE CHUNKING POR DOMINIO")
    print("=" * 60)
    
    for test_name, test_data in test_cases.items():
        domain = test_data["domain"]
        content = test_data["content"]
        
        print(f"\nüìÅ DOMINIO: {domain.upper()}")
        print("-" * 40)
        
        # Chunking tradicional (500 chars)
        try:
            from langchain.text_splitter import RecursiveCharacterTextSplitter
            traditional_splitter = RecursiveCharacterTextSplitter(
                chunk_size=500,
                chunk_overlap=50
            )
            traditional_chunks = traditional_splitter.split_text(content)
            
            print(f"üìä CHUNKING TRADICIONAL (500 chars):")
            print(f"   Chunks generados: {len(traditional_chunks)}")
            print(f"   Tama√±os: {[len(c) for c in traditional_chunks]}")
            
            # Mostrar si se cortaron elementos importantes
            if domain == "code":
                functions_cut = any("def " in chunk and not chunk.strip().endswith(":") for chunk in traditional_chunks)
                classes_cut = any("class " in chunk and not chunk.strip().endswith(":") for chunk in traditional_chunks)
                print(f"   ‚ö†Ô∏è  Funciones cortadas: {'S√≠' if functions_cut else 'No'}")
                print(f"   ‚ö†Ô∏è  Clases cortadas: {'S√≠' if classes_cut else 'No'}")
            
        except Exception as e:
            print(f"‚ùå Error en chunking tradicional: {e}")
        
        # Chunking por dominio
        try:
            domain_splitter = _get_text_splitter_for_domain(domain)
            domain_chunks = domain_splitter.split_text(content)
            
            config = CHUNKING_CONFIG[domain]
            print(f"\nüéØ CHUNKING POR DOMINIO ({config['chunk_size']} chars):")
            print(f"   Chunks generados: {len(domain_chunks)}")
            print(f"   Tama√±os: {[len(c) for c in domain_chunks]}")
            print(f"   Configuraci√≥n: {config['chunk_size']} chars, overlap {config['chunk_overlap']}")
            
            # An√°lisis espec√≠fico por dominio
            if domain == "code":
                complete_functions = sum(1 for chunk in domain_chunks if "def " in chunk and chunk.count("def ") == chunk.count("return"))
                complete_classes = sum(1 for chunk in domain_chunks if "class " in chunk and ":" in chunk)
                print(f"   ‚úÖ Funciones completas: {complete_functions}")
                print(f"   ‚úÖ Clases completas: {complete_classes}")
            
            elif domain == "documents":
                headers = sum(1 for chunk in domain_chunks if "##" in chunk)
                sections = sum(1 for chunk in domain_chunks if chunk.strip().startswith("#"))
                print(f"   ‚úÖ Headers preservados: {headers}")
                print(f"   ‚úÖ Secciones completas: {sections}")
            
        except Exception as e:
            print(f"‚ùå Error en chunking por dominio: {e}")
        
        print()
    
    # Mostrar configuraci√≥n completa
    print("\n‚öôÔ∏è CONFIGURACI√ìN DE CHUNKING POR DOMINIO")
    print("=" * 50)
    
    for domain, config in CHUNKING_CONFIG.items():
        print(f"\nüìÅ {domain.upper()}:")
        print(f"   Tama√±o: {config['chunk_size']} caracteres")
        print(f"   Overlap: {config['chunk_overlap']} caracteres")
        print(f"   Separadores: {len(config['separators'])} niveles")
        print(f"   Principales: {config['separators'][:3]}")
    
    print("\n‚ú® BENEFICIOS DEL CHUNKING POR DOMINIO:")
    print("‚Ä¢ üéØ Preserva la estructura sem√°ntica del contenido")
    print("‚Ä¢ üìè Tama√±os optimizados seg√∫n el tipo de informaci√≥n")
    print("‚Ä¢ üîç Mejor recuperaci√≥n de contexto relevante")
    print("‚Ä¢ üß† Chunks m√°s coherentes para el modelo de lenguaje")
    print("‚Ä¢ üìä Metadatos enriquecidos para an√°lisis")

if __name__ == "__main__":
    test_domain_chunking()
